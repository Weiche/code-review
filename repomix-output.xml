This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.gitignore
.python-version
config.json
main.py
mcp_manager/mcp_preset.py
prompt_preset.py
prompt.py
pyproject.toml
reports/report_2025-04-06_19_33_24.md
reports/report_2025-04-06_21_58_18.md
reports/report_2025-04-06_22_04_24.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
# Python-generated files
__pycache__/
*.py[oc]
build/
dist/
wheels/
*.egg-info
.logfire

# Virtual environments
.venv
</file>

<file path=".python-version">
3.13
</file>

<file path="config.json">
{
    "default_model": "google-gla:gemini-2.5-pro-exp-03-25",
    "mcp_servers": {
        "desktop-commander" : {
            "type": "stdio",
            "command": "npx",
            "args": [
                "-y",
                "@wonderwhy-er/desktop-commander@latest"
            ]
        },
        // {
        //     "type": "http",
        //     "host": "localhost",
        //     "port": 5000,
        //     "api_version": "v1",
        //     "timeout": 30,
        //     "max_retries": 3
        // },
        "sequential-thinking" : {
            "type": "stdio",
            "command": "npx",
            "args": [
                "-y",
                "@modelcontextprotocol/server-sequential-thinking"
            ]
        }
    },
    "logging": {
        "level": "INFO",
        "file": "mcp.log"
    }
}
</file>

<file path="main.py">
import logging
import os
import shutil
import subprocess
import sys
from datetime import datetime

import logfire
from pydantic import BaseModel
from pydantic_ai import Agent
from pydantic_ai.agent import AgentRunResult

from mcp_manager.mcp_preset import create_mcp_servers, load_config
from prompt_preset import review_default_prompts
from prompt import get_sys_prompt, get_doc_agent_sys_prompt

logfire.configure(token=os.getenv("LOGFIRE_KEY"))
logger = logging.getLogger("CodeAnalyze")

# Model name
# model_name = "deepseek:deepseek-chat"
async def generate_repomix(code_path: str) -> str | None:
    """
    Generate a repomix file for the given code path.
    Args:
        code_path (str): The path to the code directory.
    Returns:
        str | None: The content of the repomix file or None if an error occurred.
    """
    try:
        ret, output = subprocess.getstatusoutput(
            ["repomix", code_path, "-o", "repomix-output.xml"], encoding="utf-8"
        )
        if ret != 0:
            logger.error(f"repomix failed with return code {ret}")
            return None

        logger.info(f"Repomix created:{output}")
        # Assuming repomix generates a file named repomix_output.txt in the code_path directory
        # Read all contents from the file
        with open("repomix-output.xml", "r", encoding="utf-8") as file:
            content = file.read()
            return content

    except Exception as e:
        logger.error(f"Failed to create repomix, {e}")
        return None


class ReviewResult(BaseModel):
    """
    A Pydantic model representing the results of a code review analysis.
    You should use this model to structure its response when reviewing code.
    The review should assess the code on multiple dimensions including:
    - Overall quality score (0-10)
    - Readability score (0-10)
    - Maintainability score (0-10)
    - Performance score (0-10)
    - List of major issues found, including their severity and potential impact, and suggestions for resolution. if not issues found you can left it an empty list.
    - List of minor issues found, if not issues found you can left it an empty list
    - Markdown format full report

    The AI should provide constructive feedback and specific recommendations for improvement.
    """

    overall_score: int
    readability_score: int
    maintainability_score: int
    performance_score: int
    critical_issues: list[str]
    minor_issues: list[str]
    markdown_report: str


async def review_code(
    repomix_str: str, model_name: str
) -> AgentRunResult[ReviewResult]:
    """
    Review the code at the given path using the given model.
    Args:
        code_path (str): The path to the code to be reviewed.
        model_name (str): The name of the model to use for the review.
    Returns:
        ReviewResult: The results of the code review.
    """
    # Create the agent
    review_agent = Agent(
        model_name,
        system_prompt=get_sys_prompt(repomix_str),
        instrument=True,
        model_settings={"temperature": 0.0},
        result_type=ReviewResult,
    )

    result = await review_agent.run(
        user_prompt=f"""/
        {review_default_prompts["assesment"]}
        Output instruction:
        {ReviewResult.__doc__}
        """
    )
    print(f"Uses {result.usage().total_tokens} Tokens on {review_agent.model}")

    # Print scores and critical issues
    print(f"Overall Score: {result.data.overall_score}/10")
    print(f"Readability Score: {result.data.readability_score}/10")
    print(f"Maintainability Score: {result.data.maintainability_score}/10")
    print(f"Performance Score: {result.data.performance_score}/10")
    print("\nCritical Issues:")
    for issue in result.data.critical_issues:
        print(f"- {issue}")

    # Save full report to file, filename is like report_2023-10-01_12_11_00.md
    report_dir = os.path.join(os.getcwd(), "reports")
    os.makedirs(report_dir, exist_ok=True)
    report_filename = os.path.join(
        report_dir, f"report_{datetime.now().strftime('%Y-%m-%d_%H_%M_%S')}.md"
    )
    with open(report_filename, "w", encoding="utf-8") as report_file:
        report_file.write(result.data.markdown_report)
    logger.info(f"Full report saved to {report_filename}")

    return result


async def update_readme(
    repomix_str: str, 
    model_name: str
) -> None:
    """
    Update the README file with the analysis results.
    Args:
        repomix_str (str): The content of the repomix file.
        model_name (str): The name of the model used for the review.
    """
    mcp_servers = create_mcp_servers()
    doc_agent = Agent(
        model=model_name,
        system_prompt=get_doc_agent_sys_prompt(repomix_str),
        instrument=True,
        model_settings={"temperature": 0.0},
        mcp_servers=mcp_servers
    )
    if os.path.exists("Readme.md"):
        with open("Readme.md", "r", encoding="utf-8") as f:
            readme_content = f.read()
            user_prompt = f"""
            Update the contents of readme file according to the new source code.
            If the old content of old readme is totally wrong, you should rewrite the readme.
            Below is the old readme contents
            {readme_content}
            """
    else:
        user_prompt = "Generate a new Readme.md"

    async with doc_agent.run_mcp_servers():
        result = await doc_agent.run(
            user_prompt=user_prompt
        )
    logger.info(f"Token usage: {result.usage().total_tokens}")
    if result.data:
        with open("Readme.md", "w", encoding="utf-8") as f:
            f.write(result.data)


async def main():
    try:
        if not shutil.which("repomix"):
            raise ModuleNotFoundError("Need repomix to work")
        cfg = load_config()
        default_model: str = cfg.default_model
        code_path = os.path.abspath(sys.argv[1] if len(sys.argv) > 1 else os.getcwd())
        if not os.path.exists(code_path):
            raise FileNotFoundError("Code path not exist")
        # MCP Servers
        # mcp_servers: list[MCPServer] = create_mcp_servers()

    except Exception as e:
        logger.error(f"Error occured while initializing: {e}")
        exit(1)

    try:
        # Change the working directory to the code path
        os.chdir(code_path)
        logger.info(f"Current working directory: {os.getcwd()}")

        # Generate repomix
        repomix_content = await generate_repomix(code_path=code_path)

        if not repomix_content:
            raise ValueError("Failed to generate repomix")

        await review_code(repomix_str=repomix_content, model_name=default_model)
        await update_readme(repomix_str=repomix_content, model_name=default_model)

    except Exception as e:
        logger.error(f"An error occurred: {e}")
        raise e


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
</file>

<file path="mcp_manager/mcp_preset.py">
from pathlib import Path
from typing import Any, Dict, List, Optional
from pydantic import BaseModel
from pydantic_ai.mcp import MCPServer, MCPServerHTTP, MCPServerStdio
from jsoncomment import JsonComment


class StdioConfig(BaseModel):
    type: str = "stdio"
    command: str
    args: List[str]


class HTTPConfig(BaseModel):
    type: str = "http"
    host: str
    port: int
    api_version: str = "v1"
    timeout: Optional[int] = 30
    max_retries: Optional[int] = 3


MCPConfig = StdioConfig | HTTPConfig


class Config(BaseModel):
    default_model: str
    mcp_servers: Dict[str, MCPConfig]
    logging: Dict[str, Any]


def load_config() -> Config:
    config_path = Path(__file__).parent.parent / "config.json"
    try:
        parser = JsonComment()
        config_data = parser.loadf(config_path)
        return Config(**config_data)
    except Exception as e:
        raise RuntimeError(f"Failed to load config: {str(e)}")


def create_mcp_servers() -> List[MCPServer]:
    config = load_config()
    servers: List[MCPServer] = []

    for _, server_config in config.mcp_servers.items():
        if server_config.type == "stdio":
            servers.append(
                MCPServerStdio(server_config.command, args=server_config.args)
            )
        elif server_config.type == "http":
            servers.append(
                MCPServerHTTP(
                    host=server_config.host,
                    port=server_config.port,
                    api_version=server_config.api_version,
                    timeout=server_config.timeout,
                    max_retries=server_config.max_retries,
                )
            )

    return servers


if __name__ == "__main__":
    mcp_servers = create_mcp_servers()
    print(mcp_servers)
</file>

<file path="prompt_preset.py">
review_default_prompts = {
    "assesment":"""\
        Review the codebase for adherence to coding best practices and industry standards.
        Identify areas where the code could be improved in terms of readability, maintainability, and efficiency.
        Suggest specific changes to align the code with best practices.
        """
}
</file>

<file path="prompt.py">
from datetime import date


def get_sys_prompt(review_target: str) -> str:
    """
    Generate a system prompt for code review. This system prompt is a common system prompt, defines the common behavior of the agent.
    The review target is given in the system prompt for LLM cache
    Args:
        review_target (str | None): The code to be reviewed.
    Returns:
        str: The system prompt for the code review agent.
    """
    if not isinstance(review_target, str):
        raise ValueError("Invalid target for review")

    return f"""\
    You are a skilled software engineer with expertise in software development best practices.
    You review the codebase provided below for adherence to coding best practices and industry standards.
    When you point out an issue, you must specify the place in the code and its severity.
    You do not need to talk to user, just output the report.

    Code Base:
    {review_target}
    today's date = {date.today()}
    """

def get_doc_agent_sys_prompt(doc_target: str) -> str:
    """
    Generate a system prompt for documentation.
    Args:
        doc_target (str | None): The code to be reviewed.
    Returns:
        str: The system prompt for the documentation agent.
    """
    if not isinstance(doc_target, str):
        raise ValueError("Invalid target for review")

    return f"""\
    You are a skilled software engineer with expertise in software development best practices.
    You can write comprehensive documentation according to the given code base.
    The Readme.md should include:
    - Project title and description
    - Installation instructions
    - Usage examples
    - Configuration options
    - API documentation (if applicable)
    - Contribution guidelines
    - License information
    - Any other relevant sections based on the code content
    
    Write in clear, concise language and use appropriate markdown formatting.
    Include code examples where helpful and ensure all technical terms are explained.
    You do not need to talk to user, just output the full version of new document

    Code Base:
    {doc_target}
    today's date = {date.today()}
    """
</file>

<file path="pyproject.toml">
[project]
name = "code-review"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "jsoncomment>=0.4.2",
    "pydantic-ai[logfire]>=0.0.52",
]
</file>

<file path="reports/report_2025-04-06_19_33_24.md">
## Code Review Report

**Date:** 2025-04-06

### Overall Assessment

The codebase is generally well-structured, follows modern Python practices (type hints, Pydantic, async/await, pathlib), and demonstrates good configuration management and logging. The use of `pydantic-ai` for interacting with the language model and structuring the output is effective. The project setup using `pyproject.toml` is standard.

### Scores

*   **Overall Quality:** 8/10
*   **Readability:** 9/10
*   **Maintainability:** 8/10
*   **Performance:** 9/10

### Critical Issues

None identified.

### Minor Issues

1.  **`config.json`**: Using `npx -y` for MCP servers (`desktop-commander`, `sequential-thinking`) downloads and executes packages on the fly. This could introduce unexpected behavior if the remote package changes and might pose a security risk in controlled environments. Consider managing these dependencies explicitly or using pinned versions.
    *   **Severity:** Minor
    *   **File:** `config.json`
    *   **Suggestion:** Explicitly install and manage the required Node.js packages within the project or use a containerized environment where dependencies are fixed.

2.  **`main.py`**: The `generate_repomix` function hardcodes the output filename `repomix-output.xml`. This reduces flexibility.
    *   **Severity:** Minor
    *   **File:** `main.py`, line 29
    *   **Suggestion:** Consider using the `tempfile` module to generate temporary filenames or pass the desired output path as an argument.

3.  **`main.py`**: The `main` function changes the current working directory using `os.chdir(code_path)`. While convenient, changing the global working directory can sometimes lead to subtle bugs or unexpected behavior, especially if this code were part of a larger application or library. It's often safer to work with absolute paths.
    *   **Severity:** Minor
    *   **File:** `main.py`, line 81
    *   **Suggestion:** Construct absolute paths for file operations (like reading/writing reports and invoking `repomix`) based on `code_path` instead of changing the working directory.

4.  **`main.py` / `mcp_manager/mcp_preset.py`**: Several `try...except Exception` blocks are used (e.g., `main.py` lines 36, 76, 113; `mcp_manager/mcp_preset.py` line 33). While they prevent crashes, catching overly broad exceptions can sometimes mask specific errors, making debugging harder. 
    *   **Severity:** Minor
    *   **Files:** `main.py`, `mcp_manager/mcp_preset.py`
    *   **Suggestion:** Where possible, catch more specific exceptions (e.g., `FileNotFoundError`, `subprocess.CalledProcessError`, `pydantic.ValidationError`, `json.JSONDecodeError`) to allow for more targeted error handling and logging.

### Conclusion

The codebase is of good quality and adheres well to best practices. Addressing the minor issues identified would further improve its robustness and maintainability.
</file>

<file path="reports/report_2025-04-06_21_58_18.md">
## Code Review Report

**Date:** 2025-04-06

### Overall Assessment

The codebase demonstrates a strong adherence to modern Python practices. It is well-structured, utilizing type hints, asynchronous programming (`asyncio`), Pydantic for data validation and modeling, and external configuration. The project effectively leverages `pydantic-ai` for interacting with language models and structuring results. Logging is implemented, and the project structure with `pyproject.toml` is standard.

### Scores

*   **Overall Quality:** 8/10
*   **Readability:** 9/10
*   **Maintainability:** 8/10
*   **Performance:** 9/10 (Focuses on the Python code's structure; actual performance depends heavily on external processes like `repomix` and LLM API calls)

### Critical Issues

None identified.

### Minor Issues

1.  **Use of `npx -y` in Configuration:**
    *   **Severity:** Minor
    *   **File:** `config.json`
    *   **Description:** The configuration uses `npx -y @wonderwhy-er/desktop-commander@latest` and `npx -y @modelcontextprotocol/server-sequential-thinking`. This downloads and executes the latest version of the package on each run. This can lead to unexpected behavior if the remote package changes and poses a potential security risk as you are running code downloaded on the fly. It also introduces variability into the execution environment.
    *   **Suggestion:** Consider explicitly installing these Node.js dependencies within the project's environment (perhaps managed via `package.json` if Node.js is a prerequisite) or using pinned versions with `npx package@version`. Alternatively, use containerization (e.g., Docker) to ensure a consistent environment with fixed dependencies.

2.  **Hardcoded Output Filename:**
    *   **Severity:** Minor
    *   **File:** `main.py`, line 29 (within `generate_repomix`)
    *   **Description:** The filename `repomix-output.xml` is hardcoded when running the `repomix` command and when reading the file.
    *   **Suggestion:** Use the `tempfile` module to generate a temporary file path, or make the output filename configurable, perhaps passing it as an argument or deriving it dynamically.

3.  **Changing Working Directory:**
    *   **Severity:** Minor
    *   **File:** `main.py`, line 107 (within `main`)
    *   **Description:** The script changes the current working directory using `os.chdir(code_path)`. While convenient for relative path access within that directory, changing the global working directory can lead to subtle bugs and make the script harder to integrate into larger systems, as it affects the state for all subsequent operations in the process.
    *   **Suggestion:** Construct absolute paths based on `code_path` for all file operations (e.g., running `repomix`, reading/writing reports) instead of changing the working directory. Use `os.path.join(code_path, 'repomix-output.xml')` or `pathlib.Path(code_path) / 'repomix-output.xml'`.

4.  **Broad Exception Handling:**
    *   **Severity:** Minor
    *   **Files:** `main.py` (lines 36, 76, 113), `mcp_manager/mcp_preset.py` (line 33)
    *   **Description:** Several `try...except Exception as e:` blocks catch the generic `Exception` type. This can mask specific errors (e.g., `FileNotFoundError`, `subprocess.CalledProcessError`, `pydantic.ValidationError`, `json.JSONDecodeError`) and make debugging more difficult, as the exact cause of the failure is less clear from the exception type alone.
    *   **Suggestion:** Catch more specific exceptions where possible to allow for more granular error handling and logging. Retain a broad `except Exception` only at higher levels if necessary to prevent application crashes, but log the specific traceback.

5.  **Prompt Generation Redundancy:**
    *   **Severity:** Minor (Refactoring Suggestion)
    *   **File:** `prompt.py`
    *   **Description:** The functions `get_sys_prompt` and `get_doc_agent_sys_prompt` are nearly identical. They both take a target string and embed it into a similar template.
    *   **Suggestion:** Refactor these into a single function, perhaps `generate_system_prompt(target: str, task_description: str) -> str`, to reduce code duplication.

### Conclusion

The codebase is well-written and follows good software engineering principles. It is functional and leverages powerful libraries effectively. Addressing the minor issues, particularly regarding dependency management (`npx -y`), working directory changes, and specific exception handling, will enhance its robustness, security, and maintainability.
</file>

<file path="reports/report_2025-04-06_22_04_24.md">
## Code Review Report

**Date:** 2025-04-06

### Overall Assessment

The codebase provides a tool for automated code review and documentation generation using AI models via the `pydantic-ai` library. It leverages `repomix` to package the target repository and interacts with configured Model Context Protocol (MCP) servers. The code is generally well-structured, utilizes modern Python features like `asyncio`, type hints, and Pydantic for configuration and data modeling. It demonstrates good practices in configuration management, logging, and project setup.

### Scores

*   **Overall Quality:** 8/10
*   **Readability:** 9/10
*   **Maintainability:** 8/10
*   **Performance:** 9/10 (Based on Python code structure; actual performance depends on external factors like `repomix` and LLM response times)

### Critical Issues

None identified.

### Minor Issues

1.  **Dependency Execution (`npx -y @latest`)**
    *   **Severity:** Minor
    *   **File:** `config.json`
    *   **Description:** The configuration uses `npx -y ...@latest` to run MCP servers. This downloads and executes the latest version of the package on each run, which can lead to unexpected behavior due to unpinned dependencies and poses a potential security risk by running code downloaded on the fly.
    *   **Suggestion:** Pin dependency versions (e.g., `npx -y package@1.2.3`) or manage these Node.js dependencies explicitly within the project environment (e.g., using a local `package.json` and `npm install`) for better stability and security.

2.  **Changing Global Working Directory (`os.chdir`)**
    *   **Severity:** Minor
    *   **File:** `main.py`, line 107 (in `main`)
    *   **Description:** The script changes the current working directory using `os.chdir(code_path)`. Modifying the global CWD can lead to unexpected behavior, especially if this code were integrated into a larger application or used as a library. It makes reasoning about file paths less predictable.
    *   **Suggestion:** Avoid changing the working directory. Instead, construct absolute paths for all file operations (e.g., invoking `repomix`, reading/writing reports, checking for `README.md`) based on the `code_path` variable. For example, use `os.path.join(code_path, 'repomix-output.xml')` or `pathlib.Path(code_path) / 'repomix-output.xml'`.

3.  **Broad Exception Handling (`except Exception`)**
    *   **Severity:** Minor
    *   **Files:** `main.py` (lines 36, 76, 113), `mcp_manager/mcp_preset.py` (line 33)
    *   **Description:** Several `try...except Exception as e:` blocks catch the generic `Exception` type. This can mask the specific type of error that occurred (e.g., `FileNotFoundError`, `subprocess.CalledProcessError`, `pydantic.ValidationError`), making debugging and targeted error handling more difficult.
    *   **Suggestion:** Catch more specific exceptions where possible (e.g., `FileNotFoundError`, `subprocess.SubprocessError`, `ValueError`, `RuntimeError`). Retain a broad `except Exception` only at the highest level if necessary to prevent application crashes, ensuring the specific traceback is logged.

4.  **Hardcoded Filenames/Paths**
    *   **Severity:** Minor
    *   **File:** `main.py`, lines 29, 34 (in `generate_repomix`), line 90 (in `review_code`)
    *   **Description:** The temporary output filename `repomix-output.xml` and the report directory name `reports` are hardcoded.
    *   **Suggestion:** For temporary files like `repomix-output.xml`, consider using the `tempfile` module to generate unique temporary filenames/paths. For the reports directory, consider making it configurable, perhaps via `config.json` or a command-line argument.

5.  **Prompt Generation Redundancy**
    *   **Severity:** Minor (Refactoring Suggestion)
    *   **File:** `prompt.py`
    *   **Description:** The functions `get_sys_prompt` and `get_doc_agent_sys_prompt` share significant structural similarity and duplicate the persona description and code base injection logic.
    *   **Suggestion:** Consider refactoring into a single function that accepts the target code and a task-specific description/instruction set to reduce duplication and improve maintainability.

6.  **Case Sensitivity in Filename Handling**
    *   **Severity:** Minor (Nitpick)
    *   **File:** `main.py`, lines 119, 121, 133 (in `update_readme`)
    *   **Description:** The code checks for and writes to `Readme.md`. While functional on case-sensitive filesystems, the standard filename is typically `README.md`.
    *   **Suggestion:** Consistently use `README.md` for checking existence and writing the file to adhere to common conventions.

### Conclusion

The codebase is well-implemented, adhering to many modern Python best practices. It provides a solid foundation for an AI-driven code analysis tool. Addressing the minor issues identified, particularly around dependency management (`npx`), global state modification (`os.chdir`), specific exception handling, and hardcoded values, will further enhance its robustness, security, and maintainability.
</file>

</files>
